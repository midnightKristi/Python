{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "## https://github.com/shihansgit/SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_description.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m         d[term] \u001b[39m=\u001b[39m desri\n\u001b[0;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m d\n\u001b[1;32m---> 19\u001b[0m term_dictionary \u001b[39m=\u001b[39m getdict()\n\u001b[0;32m     21\u001b[0m \u001b[39m# write dictionary to csv file\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# output: two column data dictionary csv file\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_dict_to_csv\u001b[39m():\n",
      "Cell \u001b[1;32mIn [7], line 7\u001b[0m, in \u001b[0;36mgetdict\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetdict\u001b[39m():\n\u001b[0;32m      6\u001b[0m     d \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: \u001b[39m\"\u001b[39m\u001b[39mNA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     input_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mdata_description.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m input_file:\n\u001b[0;32m      9\u001b[0m         information \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_description.txt'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def getdict():\n",
    "    d = defaultdict(lambda: \"NA\")\n",
    "    input_file = open(\"data_description.txt\")\n",
    "    for line in input_file:\n",
    "        information = line.split('\\t')\n",
    "        # get rid of the information-less tuples\n",
    "        if len(information) < 2 or information[0].strip().startswith('\\n') or len(information[0])==0 or not information[0].startswith(' '):\n",
    "            continue\n",
    "        # build the dictionary from the tuples with data cleaning\n",
    "        term = information[0].strip()\n",
    "        desri = information[1].strip()\n",
    "        d[term] = desri\n",
    "    return d\n",
    "\n",
    "term_dictionary = getdict()\n",
    "\n",
    "# write dictionary to csv file\n",
    "# output: two column data dictionary csv file\n",
    "def write_dict_to_csv():\n",
    "    with open('output/term_dict.csv', 'w') as f:\n",
    "        f.write('Abbreviation,Description\\n')\n",
    "        for key in term_dictionary.keys():\n",
    "            f.write(\"%s,%s\\n\" % (key, term_dictionary[key]))\n",
    "            \n",
    "write_dict_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bonobo\n",
    "from bonobo.config import use_context_processor\n",
    "\n",
    "\n",
    "def extract():\n",
    "    yield from data.itertuples()\n",
    "\n",
    "\n",
    "# map the terms(e.g. LandSlope) to full-term in dictionary\n",
    "def transform(*args):\n",
    "    # get the index for the columns that you want to look up\n",
    "    args = list(args)\n",
    "\n",
    "    # filter out the rows (yearbuilt < 1980)\n",
    "    idx0 = category_dict['YearBuilt'] + 1\n",
    "    if int(args[idx0]) < 1980:\n",
    "        return None\n",
    "\n",
    "    # TODO: you need to replace two or three abbreviations\n",
    "    # plus 1 because the first element of args is the system idx\n",
    "    idx1 = category_dict['LandSlope'] + 1\n",
    "    idx2 = category_dict['LotShape'] + 1\n",
    "    idx3 = category_dict['LandContour'] +1\n",
    "    \n",
    "    # replace the tuple values\n",
    "    args[idx1] = term_dictionary[args[idx1]]\n",
    "    args[idx2] = term_dictionary[args[idx2]]\n",
    "    args[idx3] = term_dictionary[args[idx3]]\n",
    "    return args[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for writing to the files\n",
    "def with_opened_file1(self, context):\n",
    "    with open('output/output_lotinfo.csv', 'w+') as f1:\n",
    "        wr1 = csv.writer(f1, delimiter=',')\n",
    "        yield wr1\n",
    "        \n",
    "def with_opened_file2(self, context):       \n",
    "    with open('output/output_homeinfo.csv', 'w+') as f2:\n",
    "        wr2 = csv.writer(f2, delimiter=',')\n",
    "        yield wr2\n",
    "        \n",
    "def with_opened_file3(self, context):\n",
    "    with open('output/output_salesinfo.csv', 'w+') as f3:\n",
    "        wr3 = csv.writer(f3, delimiter=',')\n",
    "        yield wr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator is used here: every time we open the file, and append row to the existing rows, instead of overwriting it\n",
    "@use_context_processor(with_opened_file1)\n",
    "def write_repr_to_file1(wr1, *row):\n",
    "    global first_line_written\n",
    "    # uncomment to see why I need to replace \"[\" and \"]\"\n",
    "    # f.write(repr(row))\n",
    "    if row is None:\n",
    "        return\n",
    "\n",
    "    if not first_line_written:\n",
    "        wr1.writerow([category_list[a] for a in lotinfo_idx])\n",
    "        \n",
    "    tuples_lotinfo = [row[0][a] for a in lotinfo_idx]\n",
    "    wr1.writerow(tuples_lotinfo)\n",
    "\n",
    "    first_line_written = True\n",
    "    \n",
    "@use_context_processor(with_opened_file2)\n",
    "def write_repr_to_file2(wr2, *row):\n",
    "    global first_line_written\n",
    "    # uncomment to see why I need to replace \"[\" and \"]\"\n",
    "    # f.write(repr(row))\n",
    "    if row is None:\n",
    "        return\n",
    "\n",
    "    if not first_line_written:\n",
    "        wr2.writerow([category_list[a] for a in homeinfo_idx])\n",
    "        \n",
    "    tuples_homeinfo = [row[0][a] for a in homeinfo_idx]\n",
    "    wr2.writerow(tuples_homeinfo)\n",
    "    \n",
    "    first_line_written = True\n",
    "    \n",
    "\n",
    "@use_context_processor(with_opened_file3)\n",
    "def write_repr_to_file3(wr3, *row):\n",
    "    global first_line_written\n",
    "    # uncomment to see why I need to replace \"[\" and \"]\"\n",
    "    # f.write(repr(row))\n",
    "    if row is None:\n",
    "        return\n",
    "\n",
    "    if not first_line_written:\n",
    "        wr3.writerow([category_list[a] for a in salesinfo_idx])\n",
    "        \n",
    "    tuples_salesinfo = [row[0][a] for a in salesinfo_idx]\n",
    "    wr3.writerow(tuples_salesinfo)    \n",
    "    \n",
    "    first_line_written = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m first_line_written \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# prepare for the data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mISO-8859-1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# construct category dictionary (map the category to index)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m category_dict \u001b[39m=\u001b[39m defaultdict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "first_line_written = False\n",
    "\n",
    "# prepare for the data\n",
    "data = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# construct category dictionary (map the category to index)\n",
    "category_dict = defaultdict()\n",
    "category_list = data.columns.tolist()\n",
    "for i in range(len(category_list)):\n",
    "    category_dict[category_list[i]] = i\n",
    "print(category_dict)\n",
    "\n",
    "\n",
    "# divide the table into 3 sub-tables\n",
    "# TODO: The index needs to be changed according to the requirements\n",
    "lotinfo_idx = [0,3,4,5,6,7,8,9,10,11]\n",
    "homeinfo_idx = [0,15,16,17,18,19,20,21,22,23,24,25,26,27,28,\n",
    "                    29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,\n",
    "                    45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,\n",
    "                    61,62,63,64,65,66,67,68,69,70,71,72,73,74]\n",
    "salesinfo_idx = [0,75,76,77,78,79,80]\n",
    "# build Bonobo pipeline\n",
    "graph1 = bonobo.Graph()\n",
    "graph1.add_chain(\n",
    "    extract,\n",
    "    # the transform step will replace the abbr. with its full description\n",
    "    transform,\n",
    "    bonobo.Limit(100),\n",
    "    write_repr_to_file1,\n",
    ")\n",
    "bonobo.run(graph1)\n",
    "\n",
    "first_line_written = False\n",
    "\n",
    "graph2 = bonobo.Graph()\n",
    "graph2.add_chain(\n",
    "    extract,\n",
    "    # the transform step will replace the abbr. with its full description\n",
    "    transform,\n",
    "    bonobo.Limit(100),\n",
    "    write_repr_to_file2,\n",
    ")\n",
    "bonobo.run(graph2)\n",
    "\n",
    "first_line_written = False\n",
    "\n",
    "graph3 = bonobo.Graph()\n",
    "graph3.add_chain(\n",
    "    extract,\n",
    "    # the transform step will replace the abbr. with its full description\n",
    "    transform,\n",
    "    bonobo.Limit(100),\n",
    "    write_repr_to_file3,\n",
    ")\n",
    "bonobo.run(graph3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "a07631670ea0b59d0f6a9702109f8dd863ced0410ff157b7f3b35604a9dfe03e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
